{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "from scipy.signal import butter, filtfilt, freqz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import platform\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(data):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # Variables for plotting\n",
    "    n = len(data)           # total number of samples\n",
    "    T = n / fs              # seconds\n",
    "    t = np.linspace(0, T, n)\n",
    "    plt.plot(t, data, linewidth=.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MFCC_per_folder(path, cutoff=400, order=6, top_db=20):\n",
    "    wav_file_list = [f.path for f in os.scandir(path)]\n",
    "    mfcc_dataset = {}\n",
    "    for wav_file in wav_file_list:\n",
    "        \n",
    "        # Get identifier of the audio clip\n",
    "        key = re.findall('\\d+', wav_file)[0]\n",
    "        sound, sampling_rate = librosa.load(wav_file)\n",
    "        fs = sampling_rate   # sample rate, Hz\n",
    "        \n",
    "        # low-pass filter the sound by removing all frequencies\n",
    "        # above the cutoff value (default=400 Hz)\n",
    "        low_passed_sound = butter_lowpass_filter(sound, cutoff, fs, order)\n",
    "        \n",
    "        # Trim the silent parts of the speech signal\n",
    "        low_passed_trimmed_sound, _ = librosa.effects.trim(low_passed_sound, top_db=top_db)\n",
    "        \n",
    "        # Calculate the MFCC values of the low-pass filtered and trimmed speech signal\n",
    "        mfccs = librosa.feature.mfcc(y=low_passed_trimmed_sound, sr=sampling_rate, n_mfcc=12).tolist()\n",
    "        mfcc_dataset[key] = mfccs\n",
    "        \n",
    "    return mfcc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_MFCC_as_json(MFCC_data, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(MFCC_data, f, ensure_ascii=False, indent=4)\n",
    "    return None\n",
    "\n",
    "def set_path_seperator():\n",
    "    path_sep = \"/\"\n",
    "    if platform.system() == \"Windows\":\n",
    "        path_sep = \"\\\\\"\n",
    "    return path_sep\n",
    "\n",
    "\n",
    "def get_paths_of_language(source_path, language_folder, sub_folders):\n",
    "    languages = [f.name for f in os.scandir(source_path)]\n",
    "    if not language_folder in languages:\n",
    "        print('You do not have any data of this language!')\n",
    "        return None\n",
    "    else:\n",
    "        paths = []\n",
    "        for folder in sub_folders:\n",
    "            if platform.system() == 'Windows':\n",
    "                paths.append(source_path + \"\\\\\" + language_folder + \"\\\\\" + folder + \"\\\\\" + '\\\\')\n",
    "            else:\n",
    "                paths.append(source_path + \"/\" + language_folder + \"/\" + folder + \"/\")\n",
    "        return paths\n",
    "    \n",
    "def convert_to_windows_path(path):\n",
    "    return \"\\\\\".join(path.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: in case you have downloaded the data in a different audio format (for example in .mp3)\n",
    "# convert all audio files that you want to use into .wav files\n",
    "\n",
    "paths = get_paths_of_language('Downsampled', 'dummy_clips',\\\n",
    "                              ['train_wav_clips', 'test_wav_clips', 'validate_wav_clips'])\n",
    "\n",
    "# Variables needed for the filter\n",
    "order = 6\n",
    "cutoff = 400            # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "MFCC_train_set = get_MFCC_per_folder(paths[0])\n",
    "MFCC_test_set = get_MFCC_per_folder(paths[1])\n",
    "MFCC_validate_set = get_MFCC_per_folder(paths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sep = set_path_seperator()\n",
    "language_folder = paths[0].split(path_sep)[1]\n",
    "dst_folder = \"Downsampled\" + path_sep + language_folder + path_sep + 'MFCC_json_files' + path_sep\n",
    "\n",
    "sp.run(\"rm -r \" + dst_folder, shell=True)\n",
    "sp.run(\"mkdir \" + dst_folder, shell=True)\n",
    "\n",
    "# save data in json files\n",
    "save_MFCC_as_json(MFCC_train_set, dst_folder + 'MFCC_train.json')\n",
    "save_MFCC_as_json(MFCC_test_set, dst_folder + 'MFCC_test.json')\n",
    "save_MFCC_as_json(MFCC_validate_set, dst_folder + 'MFCC_validate.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
