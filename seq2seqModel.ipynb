{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "import soundfile\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Downsampled/nl/MFCC_json_files/MFCC_train.json'\n",
    "test_path = 'Downsampled/nl/MFCC_json_files/MFCC_test.json'\n",
    "validate_path = 'Downsampled/nl/MFCC_json_files/MFCC_validate.json'\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    MFCC_dataset = []\n",
    "    for key in json_data:\n",
    "        MFCC_array = np.array(json_data[key])\n",
    "        MFCC_dataset.append(MFCC_array.T)\n",
    "    return MFCC_dataset\n",
    "\n",
    "def get_max_frame_length(MFCC_dataset):\n",
    "    return max([MFCC.shape[0] for MFCC in MFCC_dataset])\n",
    "\n",
    "def pad_data(MFCC_dataset, number_of_frames):\n",
    "    padded_MFCC_dataset = []\n",
    "    for MFCC in MFCC_dataset:\n",
    "        new_MFCC = np.pad(MFCC, ((number_of_frames-MFCC.shape[0], 0), (0, 0)), 'constant')\n",
    "        padded_MFCC_dataset.append(new_MFCC)\n",
    "    return np.array(padded_MFCC_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_train_set = load_data(train_path)\n",
    "MFCC_test_set = load_data(test_path)\n",
    "MFCC_validate_set = load_data(validate_path)\n",
    "\n",
    "max_frames_train = get_max_frame_length(MFCC_train_set)\n",
    "max_frames_test = get_max_frame_length(MFCC_test_set)\n",
    "max_frames_validate = get_max_frame_length(MFCC_validate_set)\n",
    "\n",
    "new_number_of_frames = max([max_frames_train, max_frames_test, max_frames_validate])\n",
    "\n",
    "padded_MFCC_train_set = pad_data(MFCC_train_set, new_number_of_frames)\n",
    "padded_MFCC_test_set = pad_data(MFCC_test_set, new_number_of_frames)\n",
    "padded_MFCC_validate_set = pad_data(MFCC_validate_set, new_number_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3192, 378, 12)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_MFCC_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 10\n",
    "latent_dim = 150\n",
    "input_dim = 12\n",
    "timesteps = new_number_of_frames\n",
    "\n",
    "inputs = Input(shape=(input_dim, timesteps))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "sequence_autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0515 10:41:11.170021 140391068020864 deprecation.py:323] From /home/chris/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0515 10:41:12.178872 140391068020864 deprecation_wrapper.py:119] From /home/chris/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3192/3192 [==============================] - 509s 159ms/step - loss: -1996.7381\n",
      "Epoch 2/10\n",
      "3192/3192 [==============================] - 507s 159ms/step - loss: -2056.6232\n",
      "Epoch 3/10\n",
      "3192/3192 [==============================] - 1674s 524ms/step - loss: -2052.1707\n",
      "Epoch 4/10\n",
      "3192/3192 [==============================] - 507s 159ms/step - loss: -2085.7858\n",
      "Epoch 5/10\n",
      "3192/3192 [==============================] - 508s 159ms/step - loss: -2085.7869\n",
      "Epoch 6/10\n",
      "3192/3192 [==============================] - 508s 159ms/step - loss: -2085.7869\n",
      "Epoch 7/10\n",
      "3192/3192 [==============================] - 515s 161ms/step - loss: -2085.7869\n",
      "Epoch 8/10\n",
      "3192/3192 [==============================] - 510s 160ms/step - loss: -2085.7869\n",
      "Epoch 9/10\n",
      "3192/3192 [==============================] - 509s 159ms/step - loss: -2085.7869\n",
      "Epoch 10/10\n",
      "3192/3192 [==============================] - 508s 159ms/step - loss: -2085.7869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7faeebc91d68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_autoencoder.fit(padded_MFCC_train_set,\n",
    "                         padded_MFCC_train_set,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sequence_autoencoder.predict(padded_MFCC_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_signal = librosa.feature.inverse.mfcc_to_audio(prediction[0])\n",
    "soundfile.write('test_sound.wav', wav_signal, 22050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
