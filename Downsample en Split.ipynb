{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clips_size_kB(path):\n",
    "    try:\n",
    "        return int(sp.run(\"du -s \" + path, stdout=sp.PIPE, shell=True).stdout.decode(\"utf-8\").split(\"\\t\")[0])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def get_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return round(total_size/1024)\n",
    "\n",
    "def sort_age_gen_occ(df):\n",
    "    age_gen_occ_dict = {}\n",
    "    for age in dict(df.age.value_counts()):\n",
    "        for gender in [\"male\", \"female\"]:\n",
    "            age_gen_occ_dict[(age, gender)] = len(df[(df.age == age) & (df.gender == gender)])\n",
    "    age_gen_occ_list = sorted(age_gen_occ_dict, key=age_gen_occ_dict.get)\n",
    "    return age_gen_occ_dict, age_gen_occ_list\n",
    "\n",
    "def print(p=True, *args, **kwargs):\n",
    "    if type(p) == bool:\n",
    "        if p:\n",
    "            return __builtins__.print(*args, **kwargs)\n",
    "        return\n",
    "    return __builtins__.print(p, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def downsample_language(path, new_size_kB, extension=\".wav\", p=False):\n",
    "    path = '/'.join(path.split('/')) + '/'\n",
    "    old_size_kB = get_size(path + \"clips\")\n",
    "    df = pd.read_csv(path + \"validated.tsv\", sep=\"\\t\", usecols=[\"path\", \"age\", \"gender\"], dtype={\"path\": str, \"age\": str, \"gender\": str}, na_values=['NA'])\n",
    "\n",
    "    if old_size_kB <= new_size_kB:\n",
    "        print(p, \"\\nthe dataset cannot be downsampled to this size because it is not large enough\")\n",
    "        return [clip.split('.')[0] + '.' + extension.split('.')[-1] for clip in list(df.path)]\n",
    "\n",
    "    clips_needed = int((new_size_kB / old_size_kB) * len(df))\n",
    "    age_dict = dict(df.age.value_counts())\n",
    "    clips_per_group = math.ceil(clips_needed / (len(age_dict) * 2))\n",
    "    \n",
    "    age_gen_occ_dict, age_gen_occ_list = sort_age_gen_occ(df)\n",
    "    \n",
    "    selected_clips = []\n",
    "    i = 0\n",
    "    print(p, \"data length:\", len(df), \"\\t\\tclips needed:\", clips_needed)\n",
    "    for age, gender in age_gen_occ_list:\n",
    "\n",
    "        i += 1\n",
    "        current = df[(df.age == age) & (df.gender == gender)]\n",
    "        now_selected = []\n",
    "        if len(current) < clips_per_group:\n",
    "            print(p, \"\\tclips_per_group was\", clips_per_group)\n",
    "            clips_needed -= len(current)\n",
    "            try:\n",
    "                clips_per_group = math.ceil(clips_needed / ((len(age_dict) * 2) - i))\n",
    "            except ZeroDivisionError:\n",
    "                clips_per_group = clips_needed\n",
    "            now_selected = current\n",
    "            selected_clips += list(now_selected.path)\n",
    "            print(p, \"\\tnot enough clips for\", age, gender, \"so appending\", len(now_selected))\n",
    "            print(p, \"\\tclips_per_group now is\", clips_per_group)\n",
    "        else:\n",
    "            now_selected = current.sample(clips_per_group)\n",
    "            selected_clips += list(now_selected.path)\n",
    "            clips_needed -= clips_per_group\n",
    "            print(p, \"\\tenough clips for\", age, gender, \\\n",
    "                  \"(\" + str(age_gen_occ_dict[(age, gender)]), \"total), so appending\", len(now_selected))\n",
    "        df.drop(now_selected.index, inplace=True)\n",
    "        print(p, \"\\ndata length:\", len(df), \"\\t\\tclips needed:\", clips_needed)\n",
    "            \n",
    "    if clips_needed > 0:\n",
    "        if len(df) < clips_needed:\n",
    "            print(p, \"\\nnot enough labeled clips found, so appending\", clips_needed, \"unlabeled ones\")\n",
    "            selected_clips += list(df.sample(clips_needed).path)\n",
    "        else:\n",
    "            print(p, \"\\nthe dataset cannot be downsampled to this size because it is not large enough\")\n",
    "            selected_clips += list(df.path)\n",
    "            \n",
    "    return [clip.split('.')[0] + '.' + extension.split('.')[-1] for clip in selected_clips]\n",
    "        \n",
    "    \n",
    "#len(downsample_language(\"speech_data/Dutch\", 36000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_validate(data, weights):\n",
    "    if type(weights) != dict:\n",
    "        try:\n",
    "            weights = {\"train\": weights[0], \"test\": weights[1], \"validate\": weights[2]}\n",
    "        except:\n",
    "            print(\"Geen iterable\")\n",
    "            return\n",
    "        \n",
    "    weights = {k:w/sum(weights.values()) for k, w in weights.items()}\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train = data[:math.ceil(len(data) * weights[\"train\"])]\n",
    "    test = data[math.ceil(len(data) * weights[\"train\"]):\\\n",
    "                math.ceil(len(data) * (weights[\"train\"] + weights[\"test\"]))]\n",
    "    validate = data[math.ceil(len(data) * (weights[\"train\"] + weights[\"test\"])):]\n",
    "    \n",
    "    return {\"train\":train, \"test\":test, \"validate\":validate}\n",
    "    \n",
    "#len(split_train_test_validate(downsample_language(\"Data/nl\", 3000), [7, 2, 1])[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def downsample_wrapped(path, new_size_kB, extension=\".wav\", p=False, destination_name=\"/general\"):\n",
    "    path = '/'.join(path.split('/')) + '/'\n",
    "    destination = \"Downsampled/\" + path.split('/')[-2] + '/' + \\\n",
    "                '/'.join([c for c in destination_name.split('/') if c]) \n",
    "    \n",
    "#     sp.run(\"rm -r \" + destination, shell=True)\n",
    "#     sp.run(\"mkdir Downsampled\", shell=True)\n",
    "#     sp.run(\"mkdir \" + '/'.join(destination.split('/')[:2]), shell=True)\n",
    "#     sp.run(\"mkdir \" + destination, shell=True)\n",
    "\n",
    "    samples = downsample_language(path, new_size_kB, extension, p)\n",
    "    for sample in samples:\n",
    "        sp.run(\"cp \"+ path + \"clips/\" + sample + ' ' + destination, shell=True)\n",
    "    \n",
    "#downsample_wrapped(\"Data/nl\", 3000, extension=\".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def downsample_split_wrapped(path, new_size_kB, split_weights, extension=\".wav\", p=False):    \n",
    "    path = '\\\\'.join(path.split('/')) + '\\\\'\n",
    "    \n",
    "#     sp.run(\"mkdir Downsampled\", shell=True)\n",
    "#     sp.run(\"mkdir Downsampled/\" + path.split('/')[-2], shell=True)\n",
    "\n",
    "    samples = downsample_language(path, new_size_kB, extension, p)\n",
    "    splits = split_train_test_validate(samples, split_weights)\n",
    "\n",
    "    for split in splits:\n",
    "        destination = \"Downsampled\\\\\" + path.split('\\\\')[-2] + \"\\\\\" + split\n",
    "#         sp.run(\"rm -r \" + destination, shell=True)\n",
    "#         sp.run(\"mkdir \" + destination, shell=True)\n",
    "        for sample in splits[split]:\n",
    "            command = \"copy \" + path + \"clips\\\\\" + sample + ' ' + destination\n",
    "            copy = sp.run(command, shell=True)\n",
    "            #print(p, \"completed copying\", sample, \"to\", destination, \"with return code\", copy.returncode)\n",
    "            \n",
    "#downsample_split_wrapped(\"Data/nl\", 3000, [7, 2, 1], extension=\".mp3\", p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 22954 \t\tclips needed: 4869\n",
      "\tclips_per_group was 406\n",
      "\tnot enough clips for teens female so appending 0\n",
      "\tclips_per_group now is 443\n",
      "\n",
      "data length: 22954 \t\tclips needed: 4869\n",
      "\tclips_per_group was 443\n",
      "\tnot enough clips for fifties female so appending 14\n",
      "\tclips_per_group now is 486\n",
      "\n",
      "data length: 22940 \t\tclips needed: 4855\n",
      "\tclips_per_group was 486\n",
      "\tnot enough clips for thirties female so appending 15\n",
      "\tclips_per_group now is 538\n",
      "\n",
      "data length: 22925 \t\tclips needed: 4840\n",
      "\tclips_per_group was 538\n",
      "\tnot enough clips for sixties female so appending 49\n",
      "\tclips_per_group now is 599\n",
      "\n",
      "data length: 22876 \t\tclips needed: 4791\n",
      "\tclips_per_group was 599\n",
      "\tnot enough clips for fourties female so appending 50\n",
      "\tclips_per_group now is 678\n",
      "\n",
      "data length: 22826 \t\tclips needed: 4741\n",
      "\tclips_per_group was 678\n",
      "\tnot enough clips for sixties male so appending 245\n",
      "\tclips_per_group now is 750\n",
      "\n",
      "data length: 22581 \t\tclips needed: 4496\n",
      "\tclips_per_group was 750\n",
      "\tnot enough clips for twenties female so appending 302\n",
      "\tclips_per_group now is 839\n",
      "\n",
      "data length: 22279 \t\tclips needed: 4194\n",
      "\tenough clips for teens male (1304 total), so appending 839\n",
      "\n",
      "data length: 21440 \t\tclips needed: 3355\n",
      "\tenough clips for thirties male (2416 total), so appending 839\n",
      "\n",
      "data length: 20601 \t\tclips needed: 2516\n",
      "\tenough clips for fourties male (3027 total), so appending 839\n",
      "\n",
      "data length: 19762 \t\tclips needed: 1677\n",
      "\tenough clips for fifties male (4254 total), so appending 839\n",
      "\n",
      "data length: 18923 \t\tclips needed: 838\n",
      "\tenough clips for twenties male (5652 total), so appending 839\n",
      "\n",
      "data length: 18084 \t\tclips needed: -1\n",
      "data length: 56009 \t\tclips needed: 3234\n",
      "\tclips_per_group was 203\n",
      "\tnot enough clips for nineties female so appending 0\n",
      "\tclips_per_group now is 216\n",
      "\n",
      "data length: 56009 \t\tclips needed: 3234\n",
      "\tclips_per_group was 216\n",
      "\tnot enough clips for nineties male so appending 5\n",
      "\tclips_per_group now is 231\n",
      "\n",
      "data length: 56004 \t\tclips needed: 3229\n",
      "\tclips_per_group was 231\n",
      "\tnot enough clips for teens female so appending 72\n",
      "\tclips_per_group now is 243\n",
      "\n",
      "data length: 55932 \t\tclips needed: 3157\n",
      "\tclips_per_group was 243\n",
      "\tnot enough clips for sixties female so appending 138\n",
      "\tclips_per_group now is 252\n",
      "\n",
      "data length: 55794 \t\tclips needed: 3019\n",
      "\tclips_per_group was 252\n",
      "\tnot enough clips for seventies male so appending 190\n",
      "\tclips_per_group now is 258\n",
      "\n",
      "data length: 55604 \t\tclips needed: 2829\n",
      "\tenough clips for seventies female (415 total), so appending 258\n",
      "\n",
      "data length: 55346 \t\tclips needed: 2571\n",
      "\tenough clips for sixties male (487 total), so appending 258\n",
      "\n",
      "data length: 55088 \t\tclips needed: 2313\n",
      "\tenough clips for fourties female (1563 total), so appending 258\n",
      "\n",
      "data length: 54830 \t\tclips needed: 2055\n",
      "\tenough clips for thirties female (1734 total), so appending 258\n",
      "\n",
      "data length: 54572 \t\tclips needed: 1797\n",
      "\tenough clips for teens male (2418 total), so appending 258\n",
      "\n",
      "data length: 54314 \t\tclips needed: 1539\n",
      "\tenough clips for fifties female (3422 total), so appending 258\n",
      "\n",
      "data length: 54056 \t\tclips needed: 1281\n",
      "\tenough clips for twenties female (3615 total), so appending 258\n",
      "\n",
      "data length: 53798 \t\tclips needed: 1023\n",
      "\tenough clips for fifties male (3900 total), so appending 258\n",
      "\n",
      "data length: 53540 \t\tclips needed: 765\n",
      "\tenough clips for fourties male (4207 total), so appending 258\n",
      "\n",
      "data length: 53282 \t\tclips needed: 507\n",
      "\tenough clips for thirties male (5984 total), so appending 258\n",
      "\n",
      "data length: 53024 \t\tclips needed: 249\n",
      "\tenough clips for twenties male (11414 total), so appending 258\n",
      "\n",
      "data length: 52766 \t\tclips needed: -9\n",
      "data length: 112127 \t\tclips needed: 3590\n",
      "\tclips_per_group was 200\n",
      "\tnot enough clips for seventies female so appending 0\n",
      "\tclips_per_group now is 212\n",
      "\n",
      "data length: 112127 \t\tclips needed: 3590\n",
      "\tclips_per_group was 212\n",
      "\tnot enough clips for nineties male so appending 0\n",
      "\tclips_per_group now is 225\n",
      "\n",
      "data length: 112127 \t\tclips needed: 3590\n",
      "\tclips_per_group was 225\n",
      "\tnot enough clips for nineties female so appending 0\n",
      "\tclips_per_group now is 240\n",
      "\n",
      "data length: 112127 \t\tclips needed: 3590\n",
      "\tclips_per_group was 240\n",
      "\tnot enough clips for eighties male so appending 2\n",
      "\tclips_per_group now is 257\n",
      "\n",
      "data length: 112125 \t\tclips needed: 3588\n",
      "\tclips_per_group was 257\n",
      "\tnot enough clips for eighties female so appending 43\n",
      "\tclips_per_group now is 273\n",
      "\n",
      "data length: 112082 \t\tclips needed: 3545\n",
      "\tclips_per_group was 273\n",
      "\tnot enough clips for seventies male so appending 67\n",
      "\tclips_per_group now is 290\n",
      "\n",
      "data length: 112015 \t\tclips needed: 3478\n",
      "\tenough clips for sixties female (486 total), so appending 290\n",
      "\n",
      "data length: 111725 \t\tclips needed: 3188\n",
      "\tenough clips for teens female (797 total), so appending 290\n",
      "\n",
      "data length: 111435 \t\tclips needed: 2898\n",
      "\tenough clips for fifties female (947 total), so appending 290\n",
      "\n",
      "data length: 111145 \t\tclips needed: 2608\n",
      "\tenough clips for fourties female (1842 total), so appending 290\n",
      "\n",
      "data length: 110855 \t\tclips needed: 2318\n",
      "\tenough clips for thirties female (2538 total), so appending 290\n",
      "\n",
      "data length: 110565 \t\tclips needed: 2028\n",
      "\tenough clips for teens male (2683 total), so appending 290\n",
      "\n",
      "data length: 110275 \t\tclips needed: 1738\n",
      "\tenough clips for twenties female (4724 total), so appending 290\n",
      "\n",
      "data length: 109985 \t\tclips needed: 1448\n",
      "\tenough clips for fourties male (7259 total), so appending 290\n",
      "\n",
      "data length: 109695 \t\tclips needed: 1158\n",
      "\tenough clips for sixties male (11375 total), so appending 290\n",
      "\n",
      "data length: 109405 \t\tclips needed: 868\n",
      "\tenough clips for thirties male (12094 total), so appending 290\n",
      "\n",
      "data length: 109115 \t\tclips needed: 578\n",
      "\tenough clips for fifties male (13324 total), so appending 290\n",
      "\n",
      "data length: 108825 \t\tclips needed: 288\n",
      "\tenough clips for twenties male (17457 total), so appending 290\n",
      "\n",
      "data length: 108535 \t\tclips needed: -2\n",
      "data length: 854444 \t\tclips needed: 4076\n",
      "\tclips_per_group was 227\n",
      "\tnot enough clips for nineties female so appending 0\n",
      "\tclips_per_group now is 240\n",
      "\n",
      "data length: 854444 \t\tclips needed: 4076\n",
      "\tclips_per_group was 240\n",
      "\tnot enough clips for nineties male so appending 56\n",
      "\tclips_per_group now is 252\n",
      "\n",
      "data length: 854388 \t\tclips needed: 4020\n",
      "\tclips_per_group was 252\n",
      "\tnot enough clips for eighties female so appending 78\n",
      "\tclips_per_group now is 263\n",
      "\n",
      "data length: 854310 \t\tclips needed: 3942\n",
      "\tenough clips for eighties male (959 total), so appending 263\n",
      "\n",
      "data length: 854047 \t\tclips needed: 3679\n",
      "\tenough clips for seventies female (1735 total), so appending 263\n",
      "\n",
      "data length: 853784 \t\tclips needed: 3416\n",
      "\tenough clips for teens female (5908 total), so appending 263\n",
      "\n",
      "data length: 853521 \t\tclips needed: 3153\n",
      "\tenough clips for seventies male (8267 total), so appending 263\n",
      "\n",
      "data length: 853258 \t\tclips needed: 2890\n",
      "\tenough clips for sixties female (13188 total), so appending 263\n",
      "\n",
      "data length: 852995 \t\tclips needed: 2627\n",
      "\tenough clips for fourties female (17397 total), so appending 263\n",
      "\n",
      "data length: 852732 \t\tclips needed: 2364\n",
      "\tenough clips for fifties female (20220 total), so appending 263\n",
      "\n",
      "data length: 852469 \t\tclips needed: 2101\n",
      "\tenough clips for thirties female (22048 total), so appending 263\n",
      "\n",
      "data length: 852206 \t\tclips needed: 1838\n",
      "\tenough clips for fifties male (24120 total), so appending 263\n",
      "\n",
      "data length: 851943 \t\tclips needed: 1575\n",
      "\tenough clips for twenties female (26674 total), so appending 263\n",
      "\n",
      "data length: 851680 \t\tclips needed: 1312\n",
      "\tenough clips for sixties male (27641 total), so appending 263\n",
      "\n",
      "data length: 851417 \t\tclips needed: 1049\n",
      "\tenough clips for teens male (27645 total), so appending 263\n",
      "\n",
      "data length: 851154 \t\tclips needed: 786\n",
      "\tenough clips for fourties male (53489 total), so appending 263\n",
      "\n",
      "data length: 850891 \t\tclips needed: 523\n",
      "\tenough clips for thirties male (101969 total), so appending 263\n",
      "\n",
      "data length: 850628 \t\tclips needed: 260\n",
      "\tenough clips for twenties male (151945 total), so appending 263\n",
      "\n",
      "data length: 850365 \t\tclips needed: -3\n"
     ]
    }
   ],
   "source": [
    "# downsample_split_wrapped(\"E:/Users/Remco/Documents/GitHub/Scriptie/Data/nl\", 200000, [70,15,15], extension=\".mp3\", p=True)\n",
    "\n",
    "# downsample_split_wrapped(\"E:/Users/Remco/Documents/GitHub/Scriptie/Data/it\", 200000, [70,15,15], extension=\".mp3\", p=True)\n",
    "\n",
    "# downsample_split_wrapped(\"E:/Users/Remco/Documents/GitHub/Scriptie/Data/es\", 200000, [70,15,15], extension=\".mp3\", p=True)\n",
    "\n",
    "# downsample_split_wrapped(\"E:/Users/Remco/Documents/GitHub/Scriptie/Data/en\", 200000, [70,15,15], extension=\".mp3\", p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
